<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link rel="stylesheet" href="/assets/css/style.css">
<link rel="stylesheet" href="/assets/css/academicons-1.9.2/css/academicons.css">
<link rel="stylesheet" href="/assets/css/fontawesome-free-6.1.1-web/css/all.css">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">

<title>🌈 Nerf 실습 (Feat. Nerfstudio)</title>

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>🌈 Nerf 실습 (Feat. Nerfstudio) | Giseop Kim Blog</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="🌈 Nerf 실습 (Feat. Nerfstudio)" />
<meta name="author" content="Giseop Kim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Nerfstudio 를 이용해서 직접 뉴럴 렌더링을 해보자 Nerf로 대표되는 뉴럴렌더링이 요새 유행이다 (Summaries: ECCV 22, CVPR 22, ICCV 21). 최근 nerfstudio 라는 오픈소스+툴이 나왔다. 직접 해보자!" />
<meta property="og:description" content="Nerfstudio 를 이용해서 직접 뉴럴 렌더링을 해보자 Nerf로 대표되는 뉴럴렌더링이 요새 유행이다 (Summaries: ECCV 22, CVPR 22, ICCV 21). 최근 nerfstudio 라는 오픈소스+툴이 나왔다. 직접 해보자!" />
<link rel="canonical" href="http://localhost:4000/slam/2022/10/10/nerfstudio-example1.html" />
<meta property="og:url" content="http://localhost:4000/slam/2022/10/10/nerfstudio-example1.html" />
<meta property="og:site_name" content="Giseop Kim Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-10-10T08:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="🌈 Nerf 실습 (Feat. Nerfstudio)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Giseop Kim"},"dateModified":"2022-10-10T08:00:00+09:00","datePublished":"2022-10-10T08:00:00+09:00","description":"Nerfstudio 를 이용해서 직접 뉴럴 렌더링을 해보자 Nerf로 대표되는 뉴럴렌더링이 요새 유행이다 (Summaries: ECCV 22, CVPR 22, ICCV 21). 최근 nerfstudio 라는 오픈소스+툴이 나왔다. 직접 해보자!","headline":"🌈 Nerf 실습 (Feat. Nerfstudio)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/slam/2022/10/10/nerfstudio-example1.html"},"url":"http://localhost:4000/slam/2022/10/10/nerfstudio-example1.html"}</script>
<!-- End Jekyll SEO tag -->


<script type="text/javascript" src="/assets/js/darkmode.js"></script>


<!-- fabicon -->
<link rel="icon" type="image/png" href="/assets/icon/me.png">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
</head><body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/">
        
        <img src="/assets/giseopkim_thermal.png" alt="Giseop Kim" />
        
      </a>
      <h2 id="title">
        <a href="/">Giseop Kim</a>
      </h2>
      </div><p class="tagline">SLAM Engineer</p></div>
      
      <ul class="social about-footer condensed"><a href="https://www.linkedin.com/in/giseop-kim-71683088" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://scholar.google.com/citations?user=9mKOLX8AAAAJ&hl=ko&oi=ao" target="_blank">
          <li>
            <i class="ai ai-google-scholar"></i>
          </li>
        </a><a href="https://github.com/gisbi-kim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://bit.ly/giseopkim" target="_blank">
          <li>
            <i class="fa fa-user" style="font-size: 2.09em;"></i>
            <!-- <i> notion</i> -->
            <!-- <i class="fa fa-user"></i> -->
          </li>
        </a><a href="https://youtube.com/channel/UCrmVMJ3KEFbDD9EtnAmDT6g" target="_blank">
          <li>
            <i class="icon-youtube"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2024</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/slam/2022/10/10/nerfstudio-example1.html">
    <h2 class="post-title">🌈 Nerf 실습 (Feat. Nerfstudio)</h2>
  </a>
  <hr style="border:1px foo rgb(193, 198, 200)">
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Oct 10, 2022</div><ul class="post-categories"><li>SLAM</li></ul></div>
  <div class="post">
    <h1 id="nerfstudio-를-이용해서-직접-뉴럴-렌더링을-해보자">Nerfstudio 를 이용해서 직접 뉴럴 렌더링을 해보자</h1>
<ul>
  <li>Nerf로 대표되는 뉴럴렌더링이 요새 유행이다 (Summaries: <a href="https://markboss.me/post/nerf_at_eccv22/">ECCV 22</a>, <a href="https://dellaert.github.io/NeRF22/">CVPR 22</a>, <a href="https://dellaert.github.io/NeRF21/">ICCV 21</a>).</li>
  <li>최근 <a href="https://docs.nerf.studio/en/latest/">nerfstudio</a> 라는 오픈소스+툴이 나왔다.</li>
  <li>직접 해보자!</li>
</ul>

<h2 id="뉴럴-렌더링이란">뉴럴 렌더링이란</h2>
<ul>
  <li><strong>뉴럴 렌더링</strong>이란
    <ul>
      <li><a href="https://arxiv.org/abs/2111.05849">Advances in Neural Rendering (EUROGRAPHICS 2022)</a> 에서 설명한 말을 옮겨오자면
        <ul>
          <li>실세계 관측으로부터, 새로운 실감나는 이미지 (synthesizing a novel photo-realistic view) 를 생성해내는 과정 및</li>
          <li>이를 위해 컴퓨터 그래픽스와 머신러닝을 결합하는 작업이라고 한다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>이론은 (나도 잘 모른다..) 여기서는 그만 알아보도록 하고 ..</li>
</ul>

<h2 id="두괄식-요약">(두괄식) 요약</h2>
<ul>
  <li>(Nerf 계열 한정) <u>practical 하게 요약</u>하자면
    <ol>
      <li><strong>Input</strong>: discrete 한 images 들의 poses 를 알고 있으면</li>
      <li><strong>Output</strong>: 임의의 coordinate 에서 그 scene 을 바라본 view 를 얻을 수 있다.</li>
    </ol>
  </li>
  <li>바로 실전 예시를 통해 알아보자.</li>
</ul>

<h3 id="input">Input</h3>
<ul>
  <li>예를 들어, 아래 이미지들은 Galaxy S22+ 로 대충 찍어온 비디오(mp4) 에서 3hz로 추출한 사진들(png) 이다.
    <ul>
      <li>ps. 가을이 되면 카이스트 옆 유성구청 앞에서는 국화축제를 한다. 예쁘게 잘 꾸며놓는다.</li>
    </ul>
  </li>
</ul>

<p align="center">
  <iframe width="366" height="651" src="https://www.youtube.com/embed/J9-yWZRUvtY" title="ggumdori raw data for nerfstudio" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h3 id="output">Output</h3>
<ul>
  <li>단순히 위의 (not continuous한) 이미지 외에 아무런 사전정보도 주어지지 않았음에도,</li>
  <li>임의의 뷰포인트에서 포토리얼리스틱 한 이미지를 생성할 수 있다면,</li>
  <li>우리는 최종적으로 아래와 같은 smooth and continuous 한 video 를 얻을 수 있다. 이 때 이 video 의 trajectory를 사용자가 임의로 설정할 수 있다.
    <p align="center">
  <iframe width="1020" height="570" src="https://www.youtube.com/embed/YeEscls0DGA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
  </li>
  <li>이 때 “임의”의 뷰포인트에서 그 씬을 본 사실적인 뷰를 얻을 수 있으므로, 위의 비디오 외에 아래와 같이 또 다른 느낌의 비디오를 만들어볼 수도 있겠다.
    <ul>
      <li>꿈돌이가 로켓을 타고 이륙하는 느낌을 좀 더 살려보았다.</li>
    </ul>
    <p align="center">
  <iframe width="488" height="488" src="https://www.youtube.com/embed/ylgb1Vrf_Ec" title="ggumdori launch" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
  </li>
  <li>ps. 위의 novel view 에서 blurry 하거나 white noise 같은 부분들은 실제 관측치가 부족했던 부분이다 (예시: 꿈돌이 뒷편을 보는 이미지가 없었음). 따라서 더 많은 이미지가 있었다면 더 사실적인 뷰를 생성할 수 있을 것이다.</li>
</ul>

<h2 id="nerfstudio-사용법">Nerfstudio 사용법</h2>
<ul>
  <li>이제 위의 결과를 어떻게 (이론 몰라도) 얻을 수 있었는지 알아보자.</li>
  <li>막 최근(Oct, 2022)에 나온 <a href="https://docs.nerf.studio/en/latest/">Nerfstudio</a> 를 이용해보았다.
    <ul>
      <li>CLI (터미널에서 커맨드 몇번 만으로) 로 nerf 를 수행하는 툴(+라이브러리)이다.</li>
      <li>웹앱으로 뷰어도 제공하고 있어, 사용자가 <strong>코딩없이</strong> 뉴럴렌더링 결과물을 얻을 수 있는 ready-to-use product 여서 좋았다.</li>
    </ul>
  </li>
</ul>

<h3 id="단계-1-pose-얻기-command-ns-process-data">단계 1: Pose 얻기 (command: ns-process-data)</h3>
<ul>
  <li>Nerf 계열의 뉴럴렌더링은 image 들의 pose 가 주어져있을 때, novel view 를 synthesize 한다.</li>
  <li>따라서 먼저, unordered images 들의 pose 를 얻어야 한다. 이미지들의 poses 를 알기 위해서는 <a href="https://colmap.github.io/">colmap</a> 이라는 software 를 이용하면 된다.
    <ul>
      <li>이 COLMAP 부분 역시 nerfstudio 내부에 통합되어 있다. 사용자 입장에서 이부분이 매우 편했다.</li>
      <li>그래서 <a href="https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#nerfstudio-dataset">여기</a> 에 나와있는대로 <code class="language-plaintext highlighter-rouge">ns-process-data</code> 라는 커맨드 한 줄 만으로도 이미지들의 poses 를 얻을 수 있다. 이렇게 얻어진 결과물의 format 은 바로 nerfstudio 의 뒷 단계에 쓰일 수 있는 compatible 한 format 이므로, <code class="language-plaintext highlighter-rouge">ns-process-data</code> 를 이용해서 colmap을 수행하기를 추천한다.</li>
      <li>그러면 아래와 같은 결과가 생성된다.
        <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># {PROCESSED_DATA_DIR} (i.e., colmap output directory)</span>
  <span class="err">├──</span> <span class="n">colmap</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">database</span><span class="p">.</span><span class="nf">db</span>
  <span class="err">│  </span> <span class="err">└──</span> <span class="n">sparse</span>
  <span class="err">│  </span>     <span class="err">└──</span> <span class="mi">0</span>
  <span class="err">│  </span>         <span class="err">├──</span> <span class="n">cameras</span><span class="p">.</span><span class="nf">bin</span>
  <span class="err">│  </span>         <span class="err">├──</span> <span class="n">images</span><span class="p">.</span><span class="nf">bin</span>
  <span class="err">│  </span>         <span class="err">├──</span> <span class="n">points3D</span><span class="p">.</span><span class="nf">bin</span>
  <span class="err">│  </span>         <span class="err">└──</span> <span class="n">project</span><span class="p">.</span><span class="nf">ini</span>
  <span class="err">├──</span> <span class="n">images</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">frame_00001</span><span class="p">.</span><span class="nf">png</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">frame_00002</span><span class="p">.</span><span class="nf">png</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="o">...</span>
  <span class="err">├──</span> <span class="n">images_2</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">frame_00001</span><span class="p">.</span><span class="nf">png</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">frame_00002</span><span class="p">.</span><span class="nf">png</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="o">...</span>
  <span class="err">├──</span> <span class="n">images_4</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">frame_00001</span><span class="p">.</span><span class="nf">png</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">frame_00002</span><span class="p">.</span><span class="nf">png</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="o">...</span>
  <span class="err">├──</span> <span class="n">images_8</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">frame_00001</span><span class="p">.</span><span class="nf">png</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="n">frame_00002</span><span class="p">.</span><span class="nf">png</span>
  <span class="err">│  </span> <span class="err">├──</span> <span class="o">...</span>
  <span class="err">└──</span> <span class="n">transforms</span><span class="p">.</span><span class="nf">json</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>ps. COLMAP software 를 별도로 사용하게 되면 ..
    <ul>
      <li>크게 아래 3 단계로 이루어진다.
        <ol>
          <li>feature extraction</li>
          <li>feature matching</li>
          <li>bundle adjustment</li>
        </ol>
      </li>
      <li>그러면 아래와 같이 sparse 한 scene structure 와 위 이미지들의 pose (position+orientation) 를 얻을 수 있다.
        <p align="center">
       <img src="/assets/data/2022-10-09-nerfstudio-example1/colmap.png" width="950" />
  </p>
        <ul>
          <li>여기서 빨강 view 들이 poses 이고, 분홍색 lines 는 covisible feature 를 가진 views 들 사이의 관계를 보여준다.</li>
        </ul>
      </li>
      <li>ps. 위의 결과를 얻는데 역시 코딩 1도 하지 않으니 비전공자라고 겁먹을 필요는 없다. GUI에서 클릭 몇번이면 끝난다.
        <ul>
          <li>그나저나 nerfstudio 내부에 colmap data 를 생성하는 부분이 command line 한줄 (<code class="language-plaintext highlighter-rouge">ns-process-data</code>) 로 지원되고 있으므로 colmap software gui 를 켤 일 자체가 없기도 하다.</li>
        </ul>
      </li>
      <li>ps2. 위의 결과를 보면 reconstructed 된 scene이 매우 sparse 함을 알 수 있다.
        <ul>
          <li>MVS + meshing 을 거쳐서 위의 map을 더 denser 하게 만들 수 있겠으나, 보통 여전히 photo-realistic 함과는 거리가 멀다.
            <ul>
              <li>그래서 (이 한계를 해소할 수 있어서) 뉴럴 렌더링이 각광받고 있는듯하다. 물론 pose가 주어져야 하지만 이는 기존 traditional geometric methods (e.g., colmap’s sparse reconstruction and pose estimation) 가 충분히 잘 하는 일이므로 상호보완적이고 시너지가 잘 맞다!</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="단계-2-nerf-model-학습-시키기">단계 2: Nerf model 학습 시키기</h3>
<ul>
  <li>역시 커맨드라인 한줄로 이루어진다</li>
  <li>예를 들어,
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>ns-train nerfacto <span class="nt">--data</span> <span class="o">{</span>PROCESSED_DATA_DIR<span class="o">}</span>
</code></pre></div>    </div>
    <ul>
      <li>이는 nerfacto 라는 모델(방법론)을, 앞서 생성한 image 와 pose 를 이용해서, 학습시겠다는 것을 의미한다.
        <ul>
          <li>nerfacto 는 ‘사실상의 표준’을 의미하는 디팩토와 nerf 를 결합한 워딩같다. mip-nerf 와 instant-ngp 의 장점을 섞었다고 하며 nerfstudio 제작팀이 제안하는 방법인 듯하다.</li>
        </ul>
      </li>
      <li>그러면 자동으로 <code class="language-plaintext highlighter-rouge">outputs/{PROCESSED_DATA_DIR}/nerfacto/{TIME}</code>의 디렉토리가 생기고 아래에 다음과 같은 log 파일들과 weight 가 저장된다.
        <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">.</span>
<span class="err">├──</span> <span class="n">camera_path</span><span class="p">.</span><span class="nf">json</span>
<span class="err">├──</span> <span class="n">config</span><span class="p">.</span><span class="nf">yml</span>
<span class="err">├──</span> <span class="n">nerfstudio_models</span>
<span class="err">│  </span> <span class="err">└──</span> <span class="n">step</span><span class="o">-</span><span class="mo">00001</span><span class="mi">9788</span><span class="p">.</span><span class="nf">ckpt</span> <span class="c1"># saved when after 19788 iterations</span>
<span class="err">└──</span> <span class="n">viewer_log_filename</span><span class="p">.</span><span class="nf">txt</span>
</code></pre></div>        </div>
        <ul>
          <li>config.yml 에는 여러 세팅들이 담겨있으며, command line 에서 함께 전달할 수 있다.
            <ul>
              <li>예를 들어, 예전에 학습시키던 웨이트로부터 시작하고 싶다면 아래와 같이 해주면 되겠다.
                <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ns-train nerfacto <span class="nt">--data</span> <span class="o">{</span>PROCESSED_DATA_DIR<span class="o">}</span> <span class="nt">--trainer</span>.load_dir <span class="o">{</span>YOUR_WEIGHT_SAVED_DIR<span class="o">}</span>
</code></pre></div>                </div>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>그러면 학습이 시작되고, 터미널에서 webapp URI를 알려준다.
    <ul>
      <li>예를 들어 <code class="language-plaintext highlighter-rouge">https://viewer.nerf.studio/versions/22-10-07-0/?websocket_port=7007</code></li>
      <li>들어가면 아래와 같이 실시간으로 학습되는 품질 (저해상도 한정) 을 볼 수 있다.
        <p align="center">
     <img src="/assets/data/2022-10-09-nerfstudio-example1/webapp1.png" width="950" />
</p>
      </li>
      <li>그래서 학습이 진행됨에 따라 어느정도 품질에까지 도달했는지를 대충 파악해볼 수 있다.
        <ul>
          <li>위의 output 에서 소개한 비디오들은 15000 iterations 정도를 학습한 웨이트에서 얻은 결과이다.
            <ul>
              <li>1080ti 기준 + 위의 꿈돌이 데이터셋 기준 10 iteration 에 1초정도 소요되었다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="단계-3-trajectory-planning-및-비디오-제작">단계 3: trajectory planning 및 비디오 제작</h3>
<ul>
  <li>웹앱에서 또한 trajectory 도 planning 할 수 있다. 자세한건 <a href="https://www.youtube.com/watch?v=nSFsugarWzk">이 튜토리얼 영상을 참고</a>.
    <ul>
      <li>그러면 synthesize 하고 싶은 set of images 들의 trajectory 가 셋업되는데, 이 역시 커맨드를 바로 복사할 수 있도록 해줘서 매우 편리하다. 예를 들어, 다른 터미널을 켜고 <code class="language-plaintext highlighter-rouge">ns-render --load-config outputs/3hz_ns/nerfacto/2022-10-10_122640/config.yml --traj filename --camera-path-filename outputs/3hz_ns/nerfacto/2022-10-10_122640/camera_path.json --output-path renders/output.mp4</code> 이런식으로 해주면 비디오가 그저 슥슥 생성된다.</li>
    </ul>
  </li>
  <li>그 결과 최종적으로 앞서 보인 비디오 같은 결과를 얻을 수 있었다 :)
    <ul>
      <li>이 때 웹앱에서 해상도 역시 조절할 수 있다.
        <ul>
          <li>1080 x 1920 으로 제작할 때 메모리를 거의 10G 먹고, 생성속도는 15-20초에 한장 수준이었다 (1080ti 기준).</li>
          <li>600x600 에서는 메모리 6-7G 정도, 생성속도는 4-5초에 한장 수준이었다.</li>
          <li>느리긴 하다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="결론">결론</h2>
<ul>
  <li>Nerfstudio 를 이용해서 코딩없이+이론 몰라도 nerf 를 체험해볼 수 있었다!</li>
</ul>

<h3 id="todo">TODO</h3>
<ul>
  <li>mip-nerf 와 instant-ngp 를 공부해보자.</li>
</ul>

  </div>

  <hr style="border:1px foo rgb(193, 198, 200)"><div id="disqus_thread" style="margin-top:25px"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'http://localhost:4000/slam/2022/10/10/nerfstudio-example1.html';
      this.page.identifier = 'http://localhost:4000/slam/2022/10/10/nerfstudio-example1.html';
    };
    (function () {
      var d = document, s = d.createElement('script');
      s.src = 'https://robotics.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments
      powered by Disqus.</a></noscript></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://www.linkedin.com/in/giseop-kim-71683088" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://scholar.google.com/citations?user=9mKOLX8AAAAJ&hl=ko&oi=ao" target="_blank">
          <li>
            <i class="ai ai-google-scholar"></i>
          </li>
        </a><a href="https://github.com/gisbi-kim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://bit.ly/giseopkim" target="_blank">
          <li>
            <i class="fa fa-user" style="font-size: 2.09em;"></i>
            <!-- <i> notion</i> -->
            <!-- <i class="fa fa-user"></i> -->
          </li>
        </a><a href="https://youtube.com/channel/UCrmVMJ3KEFbDD9EtnAmDT6g" target="_blank">
          <li>
            <i class="icon-youtube"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2024</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/assets/js/darkmode.js"></script>
  
  <script src="/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/assets/js/search.js"></script>
  
</body>

</html>

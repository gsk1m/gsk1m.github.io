<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link rel="stylesheet" href="/assets/css/style.css">
<link rel="stylesheet" href="/assets/css/academicons-1.9.2/css/academicons.css">
<link rel="stylesheet" href="/assets/css/fontawesome-free-6.1.1-web/css/all.css">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">

<title>🌈 Error-state Kalman Filter 이야기</title>

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>🌈 Error-state Kalman Filter 이야기 | Giseop Kim Blog</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="🌈 Error-state Kalman Filter 이야기" />
<meta name="author" content="Giseop Kim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Error-state Kalman Filter 란? 최근 SLAM 학/업계에서는 visual은 OpenVINS, lidar는 Fast-LIO 가 대세가 된 듯하다. 이 둘은 모두 on-manifold EKF 혹은 error-state Kalman filter 라고 불리는 방식을 사용하고 있다. 그래서 Error-state Kalman Filter (ESKF) 에 대해 공부해보았다. 최대한 쉽게 큰그림 위주로 이해해보자." />
<meta property="og:description" content="Error-state Kalman Filter 란? 최근 SLAM 학/업계에서는 visual은 OpenVINS, lidar는 Fast-LIO 가 대세가 된 듯하다. 이 둘은 모두 on-manifold EKF 혹은 error-state Kalman filter 라고 불리는 방식을 사용하고 있다. 그래서 Error-state Kalman Filter (ESKF) 에 대해 공부해보았다. 최대한 쉽게 큰그림 위주로 이해해보자." />
<link rel="canonical" href="http://localhost:4000/slam/2022/09/24/kf-tutorial1.html" />
<meta property="og:url" content="http://localhost:4000/slam/2022/09/24/kf-tutorial1.html" />
<meta property="og:site_name" content="Giseop Kim Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-09-24T08:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="🌈 Error-state Kalman Filter 이야기" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Giseop Kim"},"dateModified":"2022-09-24T08:00:00+09:00","datePublished":"2022-09-24T08:00:00+09:00","description":"Error-state Kalman Filter 란? 최근 SLAM 학/업계에서는 visual은 OpenVINS, lidar는 Fast-LIO 가 대세가 된 듯하다. 이 둘은 모두 on-manifold EKF 혹은 error-state Kalman filter 라고 불리는 방식을 사용하고 있다. 그래서 Error-state Kalman Filter (ESKF) 에 대해 공부해보았다. 최대한 쉽게 큰그림 위주로 이해해보자.","headline":"🌈 Error-state Kalman Filter 이야기","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/slam/2022/09/24/kf-tutorial1.html"},"url":"http://localhost:4000/slam/2022/09/24/kf-tutorial1.html"}</script>
<!-- End Jekyll SEO tag -->


<script type="text/javascript" src="/assets/js/darkmode.js"></script>


<!-- fabicon -->
<link rel="icon" type="image/png" href="/assets/icon/me.png">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
</head><body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/">
        
        <img src="/assets/giseopkim_thermal.png" alt="Giseop Kim" />
        
      </a>
      <h2 id="title">
        <a href="/">Giseop Kim</a>
      </h2>
      </div><p class="tagline">SLAM Engineer</p></div>
      
      <ul class="social about-footer condensed"><a href="https://www.linkedin.com/in/giseop-kim-71683088" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://scholar.google.com/citations?user=9mKOLX8AAAAJ&hl=ko&oi=ao" target="_blank">
          <li>
            <i class="ai ai-google-scholar"></i>
          </li>
        </a><a href="https://github.com/gisbi-kim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://bit.ly/giseopkim" target="_blank">
          <li>
            <i class="fa fa-user" style="font-size: 2.09em;"></i>
            <!-- <i> notion</i> -->
            <!-- <i class="fa fa-user"></i> -->
          </li>
        </a><a href="https://youtube.com/channel/UCrmVMJ3KEFbDD9EtnAmDT6g" target="_blank">
          <li>
            <i class="icon-youtube"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2022</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/slam/2022/09/24/kf-tutorial1.html">
    <h2 class="post-title">🌈 Error-state Kalman Filter 이야기</h2>
  </a>
  <hr style="border:1px foo rgb(193, 198, 200)">
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Sep 24, 2022</div><ul class="post-categories"><li>SLAM</li></ul></div>
  <div class="post">
    <h1 id="error-state-kalman-filter-란">Error-state Kalman Filter 란?</h1>
<ul>
  <li>최근 SLAM 학/업계에서는 visual은 <a href="https://github.com/rpng/open_vins">OpenVINS</a>, lidar는 <a href="https://github.com/hku-mars/FAST_LIO">Fast-LIO</a> 가 대세가 된 듯하다.
    <ul>
      <li>이 둘은 모두 <strong><code class="language-plaintext highlighter-rouge">on-manifold EKF</code></strong> 혹은 <strong><code class="language-plaintext highlighter-rouge">error-state Kalman filter</code></strong> 라고 불리는 방식을 사용하고 있다.</li>
    </ul>
  </li>
  <li>그래서 Error-state Kalman Filter (ESKF) 에 대해 공부해보았다.</li>
  <li>최대한 쉽게 큰그림 위주로 이해해보자.</li>
</ul>

<h2 id="큰-그림">큰 그림</h2>
<ul>
  <li>일단 ESKF에 대해 이야기 하려면
    <ol>
      <li>EKF (Extended Kalman Filter)를 알아야 하고</li>
      <li>그 전에 KF (Kalman Filter)를 알아야 한다.</li>
      <li>그리고 GN (Gauss-Newton) Opt 에 대해서도 이해해야 한다.</li>
    </ol>
  </li>
  <li>뭔가 많아 보이지만, 큰 그림에서 수학없이 이야기해보는 것이 이 포스트의 목적이다.</li>
</ul>

<h3 id="kf-톺아보기">KF 톺아보기</h3>
<ul>
  <li>KF 에 대한 (수학적) 설명을 여기서 늘어놓을 생각은 없다..
    <ul>
      <li>KF를 약간 무식하게 한줄 요약하자면 1. 저질러보고, 2. 수정하기, 라고 할 수 있다.
        <ul>
          <li>예를 들어 현재 벽으로부터 내가 1m 떨어져서 서있음을 안다. 그리고 내 보폭 한 칸은 50cm 정도 되고 내 팔길이는 50cm 라고 하자. 내가 앞으로 한칸 움직이면 나는 벽으로부터 얼마나 떨어져있을까?
            <ol>
              <li>저질러보기: 일단 움직이자! 50cm 라고 치자. 그러면 나는 벽으로부터 100-50 = 50 cm 만큼 떨어져있겠지?
                <ul>
                  <li>하지만 문제는 보폭이 항상 정밀하게 딱 50cm 일리는 만무하다.</li>
                </ul>
              </li>
              <li>수정하기: 그래서 팔을 한번 뻗어보았다. 근데 팔을 끝까지 쭉 뻗었는데도 공간이 조금 남네. 그러면 50cm 보다는 일단 덜 간 건 알겠다. 그럼 아까 50cm 떨어져있다고 저질렀던 예측값을 조금 수정해주면 되겠다.</li>
            </ol>
          </li>
          <li>근데 팔길이로 길이를 대충 재는 것도 엄청 정밀하지는 않은데.
            <ul>
              <li>나는 벽으로부터 60cm 떨어져있다고 해야 하나..? 55cm 떨어져있다고 해야 하나..? 보폭과 팔길이기반측정 의 결과를 서로 다른 신뢰도에 기반해서 어떻게 적절히 잘 융합할 수 없을까? 그것에 대한 수학적인 기계적 과정을 제공하는 것이 KF라고 할 수 있다.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>이에 대한 공부자료는 <a href="https://www.cs.unc.edu/~welch/media/pdf/kalman_intro.pdf">An Introduction to the Kalman Filter (2006 ver)</a> 를 추천한다.
        <ul>
          <li>KF 공부자료야 워낙 많지만… 이게 가장 분량도 적절한 듯하다 (너무 생략되어있거나 너무 쓸데없이 입문자에게 불필요하게 많지않다).</li>
          <li>95년에 처음 나온 report 인데 현재 (2022.09) 무려 10000회 인용이 넘었다. 이 report 는 되게 간결한 편이며 더욱 자세한 유도 등은 여기에 reference 들이 잘 추천되어 있으므로 (e.g., Maybeck79) 추가적으로 더 공부하고 싶으면 참고하면 좋다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>요약하자면 KF는 prior (저질러 본 것)와 measurement (재 본 것) 사이의 weighted sum (두 결과 토대로 수정한 것)을 해주는 장치이다.
    <ul>
      <li>이 때 고정된 상수로 융합하는 게 아니라, <strong><code class="language-plaintext highlighter-rouge">a posteriori 의 covariance 를 minimize 하는 것을 cost</code></strong> 로 하여 최적 gain 을 결정하는 방법이다 (따라서 Kalman gain 은 <code class="language-plaintext highlighter-rouge">blending factor</code>라고도 불린다).</li>
      <li>암튼 핵심은 KF는 방금 설명했듯 <code class="language-plaintext highlighter-rouge">a posteriori 의 covariance 를 minimize</code> 하는 것을 목표로 하기 때문에, <code class="language-plaintext highlighter-rouge">optimal estimator</code> 라고 불린다.
        <ul>
          <li>혹은 <a href="https://en.wikipedia.org/wiki/Kalman_filter">위키를 보면</a>, KF는 <code class="language-plaintext highlighter-rouge">linear quadratic estimation (LQE)</code> 라고도 불린다고 나와있다.
            <ul>
              <li>covariance 는 그 정의상 random variable error vector의 제곱꼴이기 때문이다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>잡썰
    <ul>
      <li>ps1. Phil’s Lab 의 유튜브 영상도 KF에 대해 정말 이해하기 쉽게 잘 설명해준다. 추천! (<a href="https://www.youtube.com/watch?v=RZd6XDx5VXo">1편</a>, <a href="https://www.youtube.com/watch?v=BUW2OdAtzBw">2편</a>, <a href="https://www.youtube.com/watch?v=hQUkiC5o0JI">3편</a>, <a href="https://youtu.be/7HVPjkWOrLE">4편</a>)
        <ul>
          <li>2편에서 상수 weight 비율로 fusion 하는 (e.g,, 0.5 and 0.5) complementary filter 를 먼저 보여주고 EKF로 넘어가는 스토리가 아주 일품이다. 그리고 실제로 IMU 센서 데이터를 통해 결과를 보여주기 때문에 KF 가 현실세계와 동떨어진 무언가로 느껴지지 않는다.</li>
        </ul>
      </li>
      <li>ps2. KF에서 prior 라는 용어가 꼭 매우 최초의 어떤 정보만을 의미하지는 않는다. KF는 Bayesian filtering 이며 Bayesian filtering 의 철학은 현재의 최적값이, 다음 턴의 사전정보가 된다, 이기 때문이다. 즉 현재의 posterior 가 다음 턴의 prior 로써 역할하는 것.
        <ul>
          <li>그나저나 Bayesian filtering 이야기가 나온 김에… KF는 원래 상당히 최적화 스러운 (== least square optimization 스러운) 느낌으로부터 유도 되었지만 (방금 말했듯 cov를 최소화 하도록), 그 nature 를 들여다보면 Probabilistic한 면이 있다. 이 이야기가 <code class="language-plaintext highlighter-rouge">The Probabilistic Origins of the Filter</code> 라면서 위에서 추천한 자료에도 나온다. 또는 Särkkä, Simo. Bayesian filtering and smoothing. No. 3. Cambridge University Press, 2013. 이 책의 앞부분을 참고 (<a href="https://gisbi-kim.github.io/blog/2021/03/09/bayesfiltering-1.html">요약 1편</a>, <a href="https://gisbi-kim.github.io/blog/2021/03/09/bayesfiltering-2.html">요약 2편</a>).</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="ekf-톺아보기">EKF 톺아보기</h3>
<ul>
  <li>이제 우리는 KF에 대해 알았다. 그럼 EKF로 넘어가보자.
    <ul>
      <li>(E-, ES-) KF류를 구성하기 위해서는 가장 먼저 system model이 정의되어야 한다.
        <ul>
          <li>
            <ol>
              <li>process model 과 2. measurement model 이 있다.</li>
            </ol>
          </li>
        </ul>
      </li>
      <li>앞서 공부자료 <a href="https://www.cs.unc.edu/~welch/media/pdf/kalman_intro.pdf">An Introduction to the Kalman Filter (2006 ver)</a> 의 식 1.1, 1.2 에서처럼 이 모델들이, 우리가 알고싶은 state 나 measurement vector 와 그저 matrix 곱으로 이루어져 있으면 linear 하다라고 한다.</li>
      <li>그런데 현실세계에서는 다양한 이유들로 인해 nonlinearity가 생긴다.
        <ul>
          <li>state 가 nonlinear 할 수 있다 (e.g., rotation 을 추정하고 싶은 경우)</li>
          <li>혹은 measurement model 이 nonlinear 할 수 있다 (e.g., 제곱, exponential 등등이 들어가는 복잡한 형태)</li>
        </ul>
      </li>
      <li>그래서 이런 nonlinear 한 process model $f(\cdot)$ or observation model $h(\cdot)$ 을 테일러 급수로 편 다음에 1차 근사 (== linear term만 남김) 해서 쓰겠다는게 EKF이다.</li>
    </ul>
  </li>
</ul>

<h3 id="eskf-톺아보기--전에">ESKF 톺아보기 … 전에</h3>
<ul>
  <li>그럼 EKF와 ESKF는 무엇이 다른가?</li>
  <li>이 이야기를 하기 전에 우리는 잠시 KF 라는 것 자체로부터 멀어질 필요가 있다.</li>
  <li>즉 ESKF 와 EKF는 이렇게 달라, 하고 그 물질적인 면을 보고 외우는 것보다, 무엇보다 ESKF가 왜 필요하게 되었는지를 살펴보자는 것이다.
    <ul>
      <li>키워드 힌트: EKF on manifold
        <ul>
          <li>즉, manifold 에서 EKF를 하려면 뭔가 좀 특별하게 care 해줘야 할 게 있다는 것인데. 이게 뭔소린가 하니 차차 알아보자.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>앞서 KF도 optimal estimator 라고 했다. 즉 covariance 라는 squared loss 를 최소화 하는 최적화기기 인 것이다.
    <ul>
      <li>즉 이부분에서 KF는 least square optimization 의 대표주자인 Gauss-Netwon optimization (GN) 을 닮았다.
        <ul>
          <li>GN (or can be LM, just damping 이 추가된 GN)이 변화량이 어느정도보다 작아질 때까지 계속 iteration 을 반복해서 $\delta \textbf{x}^*$ 를 찾아가는 것이라면 (for details, see the post: <a href="https://gsk1m.github.io/slam/2022/07/09/symforce_icp.html">Nonlinear ICP 밑바닥부터 구현해보기</a>),</li>
          <li>KF는 최적의 weight 비율을 한방에 딱 찾아내서 딱 한번만 update 해주는 GN optimizer 라고 생각해볼 수 있다는 것이다 (완전히 같다는 게 아니라, 그 느낌만 비교하자..).
            <ul>
              <li>ps. 물론 KF에서도, 한번의 propagate 에 대해 여러번의 (수렴할 때까지) update 를 해주는 방식으로 iterative 하게 구성할 수 있긴하다 (<a href="https://github.com/artivis/manif/blob/devel/examples/se3_localization_iekf.cpp">예시: se3_localization_iekf</a>)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>그래서 GN 이야기를 좀 더 해보자.</li>
    </ul>
  </li>
</ul>

<h3 id="gn-톺아보기">GN 톺아보기</h3>
<ul>
  <li>GN에서 개념 자체는 너무 간단하다.
    <ul>
      <li>기본적인 개념에 대해서는 늘 추천하는 <a href="http://www.diag.uniroma1.it//~labrococo/tutorial_icra_2016/icra16_slam_tutorial_grisetti.pdf">Grisetti 교수님의 ICRA tutorial 자료</a>를 보고 오기를 추천… 하고 여기서는 GN 에 대해서는 설명하지 않기로 하고.</li>
      <li>결과만 이야기하자면 GN이란 그저 $J^{T}J \delta \textbf{x} = -J^{T}e$ 를 푸는게 전부이다.
        <ul>
          <li>이걸 풀어서 나온 $\delta \textbf{x}^{*}$ 를 기존 해 $\textbf{x}$ 에 더해주면 된다. 그리고 $\delta \textbf{x}$ 가 충분히 작다면 수렴한 것으로 보고 iteration 을 종료하면 된다. 이걸 from scratch (밑바닥부터)로 구현해본 것이 the previous post: <a href="https://gsk1m.github.io/slam/2022/09/01/robust-opt-tutorial1.html">Robust Optimization Tutorial</a>.</li>
        </ul>
      </li>
      <li>그런데 이부분은 정말 기계적인 부분이고. 중요한 지점은 저 $J$ 란게 뭐냐, 하는 것이다.</li>
    </ul>
  </li>
  <li>TBA</li>
</ul>

  </div>

  <hr style="border:1px foo rgb(193, 198, 200)"><div id="disqus_thread" style="margin-top:25px"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'http://localhost:4000/slam/2022/09/24/kf-tutorial1.html';
      this.page.identifier = 'http://localhost:4000/slam/2022/09/24/kf-tutorial1.html';
    };
    (function () {
      var d = document, s = d.createElement('script');
      s.src = 'https://robotics.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments
      powered by Disqus.</a></noscript></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://www.linkedin.com/in/giseop-kim-71683088" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://scholar.google.com/citations?user=9mKOLX8AAAAJ&hl=ko&oi=ao" target="_blank">
          <li>
            <i class="ai ai-google-scholar"></i>
          </li>
        </a><a href="https://github.com/gisbi-kim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://bit.ly/giseopkim" target="_blank">
          <li>
            <i class="fa fa-user" style="font-size: 2.09em;"></i>
            <!-- <i> notion</i> -->
            <!-- <i class="fa fa-user"></i> -->
          </li>
        </a><a href="https://youtube.com/channel/UCrmVMJ3KEFbDD9EtnAmDT6g" target="_blank">
          <li>
            <i class="icon-youtube"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2022</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/assets/js/darkmode.js"></script>
  
  <script src="/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/assets/js/search.js"></script>
  
</body>

</html>

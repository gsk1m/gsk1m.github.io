<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link rel="stylesheet" href="/assets/css/style.css">
<link rel="stylesheet" href="/assets/css/academicons-1.9.2/css/academicons.css">
<link rel="stylesheet" href="/assets/css/fontawesome-free-6.1.1-web/css/all.css">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">

<title>🌈 IMU와 LiDAR를 퓨전해야 하는 이유 2 (Feat. PyPose and Open3D)</title>

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>🌈 IMU와 LiDAR를 퓨전해야 하는 이유 2 (Feat. PyPose and Open3D) | Giseop Kim Blog</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="🌈 IMU와 LiDAR를 퓨전해야 하는 이유 2 (Feat. PyPose and Open3D)" />
<meta name="author" content="Giseop Kim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Loosely-coupled Lidar-Inertial odometry 실습 저번 블로그 글 에서 IMU만으로 odometry (즉, relative motion 추정) 를 하기 위해서는 global attidue가 중요함을 알아보았다. 물론 PVA (position, velocity, attitude) 가 모두 중요하다. 하지만 값비싼 GPS+INS 없이도, LiDAR 센서를 이용해서 이러한 보정을 해줄 수 있다. Python만 이용해서 간단하게 loosely-coupled lidar-inertial odometry (a.k.a mini-pyllio) 를 구현해보자." />
<meta property="og:description" content="Loosely-coupled Lidar-Inertial odometry 실습 저번 블로그 글 에서 IMU만으로 odometry (즉, relative motion 추정) 를 하기 위해서는 global attidue가 중요함을 알아보았다. 물론 PVA (position, velocity, attitude) 가 모두 중요하다. 하지만 값비싼 GPS+INS 없이도, LiDAR 센서를 이용해서 이러한 보정을 해줄 수 있다. Python만 이용해서 간단하게 loosely-coupled lidar-inertial odometry (a.k.a mini-pyllio) 를 구현해보자." />
<link rel="canonical" href="http://localhost:4000/slam/2023/01/09/imu-lidar-fusion2.html" />
<meta property="og:url" content="http://localhost:4000/slam/2023/01/09/imu-lidar-fusion2.html" />
<meta property="og:site_name" content="Giseop Kim Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-01-09T09:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="🌈 IMU와 LiDAR를 퓨전해야 하는 이유 2 (Feat. PyPose and Open3D)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Giseop Kim"},"dateModified":"2023-01-09T09:00:00+09:00","datePublished":"2023-01-09T09:00:00+09:00","description":"Loosely-coupled Lidar-Inertial odometry 실습 저번 블로그 글 에서 IMU만으로 odometry (즉, relative motion 추정) 를 하기 위해서는 global attidue가 중요함을 알아보았다. 물론 PVA (position, velocity, attitude) 가 모두 중요하다. 하지만 값비싼 GPS+INS 없이도, LiDAR 센서를 이용해서 이러한 보정을 해줄 수 있다. Python만 이용해서 간단하게 loosely-coupled lidar-inertial odometry (a.k.a mini-pyllio) 를 구현해보자.","headline":"🌈 IMU와 LiDAR를 퓨전해야 하는 이유 2 (Feat. PyPose and Open3D)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/slam/2023/01/09/imu-lidar-fusion2.html"},"url":"http://localhost:4000/slam/2023/01/09/imu-lidar-fusion2.html"}</script>
<!-- End Jekyll SEO tag -->


<script type="text/javascript" src="/assets/js/darkmode.js"></script>


<!-- fabicon -->
<link rel="icon" type="image/png" href="/assets/icon/me.png">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
</head><body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/">
        
        <img src="/assets/giseopkim_thermal.png" alt="Giseop Kim" />
        
      </a>
      <h2 id="title">
        <a href="/">Giseop Kim</a>
      </h2>
      </div><p class="tagline">SLAM Engineer</p></div>
      
      <ul class="social about-footer condensed"><a href="https://www.linkedin.com/in/giseop-kim-71683088" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://scholar.google.com/citations?user=9mKOLX8AAAAJ&hl=ko&oi=ao" target="_blank">
          <li>
            <i class="ai ai-google-scholar"></i>
          </li>
        </a><a href="https://github.com/gisbi-kim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://bit.ly/giseopkim" target="_blank">
          <li>
            <i class="fa fa-user" style="font-size: 2.09em;"></i>
            <!-- <i> notion</i> -->
            <!-- <i class="fa fa-user"></i> -->
          </li>
        </a><a href="https://youtube.com/channel/UCrmVMJ3KEFbDD9EtnAmDT6g" target="_blank">
          <li>
            <i class="icon-youtube"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2023</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/slam/2023/01/09/imu-lidar-fusion2.html">
    <h2 class="post-title">🌈 IMU와 LiDAR를 퓨전해야 하는 이유 2 (Feat. PyPose and Open3D)</h2>
  </a>
  <hr style="border:1px foo rgb(193, 198, 200)">
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Jan 9, 2023</div><ul class="post-categories"><li>SLAM</li></ul></div>
  <div class="post">
    <h1 id="loosely-coupled-lidar-inertial-odometry-실습">Loosely-coupled Lidar-Inertial odometry 실습</h1>
<ul>
  <li><a href="/slam/2023/01/01/imu-lidar-fusion1.html"> 저번 블로그 글 </a> 에서 IMU만으로 odometry (즉, relative motion 추정) 를 하기 위해서는 global attidue가 중요함을 알아보았다.
    <ul>
      <li>물론 PVA (position, velocity, attitude) 가 모두 중요하다.
<!-- - LiDAR scan matching (e.g., ICP) 이 PVA correction 을 해줄 수 있다. 좋은 global pose를 공급받은 IMU는 더 좋은 IMU odometry 를 생성한다. => 이는 다음 턴의 ICP가 잘 수행되기 위한 좋은 이니셜이 된다. => 좋은 이니셜을 공급받은 좋은 registration이 IMU의 state (i.e., PVA) 를 더 잘 보정한다 => 좋은 IMU pose 는 좋은 IMU odometry를 생성한다 => ICP가 잘 된다 => IMU의 pose 가 또 잘 보정된다 => ... --></li>
    </ul>
  </li>
  <li>하지만 값비싼 GPS+INS 없이도, LiDAR 센서를 이용해서 이러한 보정을 해줄 수 있다.</li>
  <li>Python만 이용해서 간단하게 <strong>loosely-coupled lidar-inertial odometry</strong> (a.k.a mini-pyllio) 를 구현해보자.</li>
</ul>

<h2 id="개요">개요</h2>
<ul>
  <li><a href="/slam/2023/01/01/imu-lidar-fusion1.html"> 저번 블로그 글 </a> 에서 IMU만으로 odometry (즉, relative motion 추정) 를 하기 위해서는 global attidue가 중요함을 알아보았다.</li>
  <li>KITTI dataset 에서 제공하는 값비싼 GPS+INS 센서 (== oxts) 가 제공하는 Global rotation 을 공급한 경우, 이 값으로 중력을 잘 보상해줄 수 있었고, 결과적으로 유효한 가속도를 계산할 수 있게 되고, 이는 velocity 와 position 예측을 더 잘 할 수 있게 해주었다.</li>
  <li>하지만 값비싼 GPS+INS 시스템을 사용할 수 없다면 어떻게 해야 할까? 혹은 실내에서 GPS 신호가 공급되지 않을 때에는 어떻게 해야할까?</li>
  <li>LiDAR 를 이용해서 이 역할을 대신해보자.</li>
</ul>

<h2 id="구현">구현</h2>
<h3 id="목적">목적</h3>
<ul>
  <li>Python 만을 이용해서 최소한의 코드로 구현하는 것이 목적이었다.
    <ul>
      <li>IMU propagation 은 Pypose 를 사용하였고, LiDAR scan-to-scan registration 은 Open3D 를 사용하였다.</li>
    </ul>
  </li>
</ul>

<h3 id="구현체">구현체</h3>
<ul>
  <li><a href="https://github.com/gisbi-kim/mini-pyllio">https://github.com/gisbi-kim/mini-pyllio</a>
    <ul>
      <li>실습하는 방법은 github readme 를 참고.</li>
    </ul>
  </li>
</ul>

<h3 id="톺아보기">톺아보기</h3>
<ul>
  <li>메인부분만 보면 다음과 같이 간단하다.
    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># state estimation for a KITTI dataset raw data sequence (e.g., 2011_09_30_0018)</span>
  <span class="n">llio</span> <span class="o">=</span> <span class="no">LLIO</span><span class="p">(</span><span class="s2">"cfg.yml"</span><span class="p">)</span>
  <span class="n">llio</span><span class="p">.</span><span class="nf">init_integrator</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span> <span class="k">in</span> <span class="n">enumerate</span><span class="p">(</span><span class="n">llio</span><span class="p">.</span><span class="nf">dataloader</span><span class="p">):</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">llio</span><span class="p">.</span><span class="nf">propogate</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">llio</span><span class="p">.</span><span class="nf">correct</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">llio</span><span class="p">.</span><span class="nf">cfg</span><span class="p">[</span><span class="s2">"use_lidar_correction"</span><span class="p">])</span>

      <span class="n">llio</span><span class="p">.</span><span class="nf">append_log</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

  <span class="n">llio</span><span class="p">.</span><span class="nf">visualize_traj</span><span class="p">()</span>
</code></pre></div>    </div>
    <ul>
      <li>제일 마지막에 결과를 그리도록 하였다 (<code class="language-plaintext highlighter-rouge">visualize_traj()</code>).</li>
    </ul>
  </li>
  <li>단계별로 요약해보자면:
    <ol>
      <li>준비 단계
        <ul>
          <li><code class="language-plaintext highlighter-rouge">LLIO</code> (Loosely-coupled LiDAR Inertial Odometry) 객체를 생성하면 dataset을 load 한다.
            <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="nb">self</span><span class="p">):</span>
     <span class="nb">self</span><span class="p">.</span><span class="nf">dataset</span> <span class="o">=</span> <span class="no">KittiDataloader</span><span class="p">(</span>
         <span class="nb">self</span><span class="p">.</span><span class="nf">cfg</span><span class="p">[</span><span class="s2">"input"</span><span class="p">][</span><span class="s2">"dataroot"</span><span class="p">],</span>
         <span class="nb">self</span><span class="p">.</span><span class="nf">cfg</span><span class="p">[</span><span class="s2">"input"</span><span class="p">][</span><span class="s2">"dataname"</span><span class="p">],</span>
         <span class="nb">self</span><span class="p">.</span><span class="nf">cfg</span><span class="p">[</span><span class="s2">"input"</span><span class="p">][</span><span class="s2">"datadrive"</span><span class="p">],</span>
         <span class="n">duration</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="nf">cfg</span><span class="p">[</span><span class="s2">"step_size"</span><span class="p">],</span>
         <span class="n">step_size</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="nf">cfg</span><span class="p">[</span><span class="s2">"step_size"</span><span class="p">],</span>
     <span class="p">)</span>
</code></pre></div>            </div>
          </li>
          <li>교육용 목적이기 때문에 lidar scan 을 한번에 다 읽어서 메모리에 올리도록 간단하게 구현하였다. 그래서 수 초가 소요되고 (데이터셋의 크기에 따라) 수G 정도의 여분의 메모리가 필요할 수 있다 (ps. 2011_09_30_0020 가 frame이 1000개 정도되는 꽤 짧은 시퀀스이기 때문에 이걸로 실습하면 편리할 것이다).</li>
          <li>위의 configuration에서 <code class="language-plaintext highlighter-rouge">step_size</code> 는 lidar aiding 을 받을 간격을 의미한다.
            <ul>
              <li>예를 들어 5로 설정하면, LiDAR 는 5 frame 마다 한번씩만 보정을 한다. 보정하지 않는 나머지 4 프레임 간격에 대해서는 보정없이, imu only로 propagation 을 한다라고 생각하면 된다.</li>
              <li>실제로도, IMU (보통 100hz 이상) 보다 LiDAR 센서 (10hz) 의 frame 이 더 sparse 하게 들어오기 때문에, correction 은 sparse 하게 일어나고, propagation 은 더 자주 일어나는 상황이 일반적이다. 그래서 보통은 모든 lidar frame 에 대해서 correction을 수행할 수 있다 (그것보다 이미 imu hz가 더 높기 때문에).</li>
              <li>다만 이 실습예제에서는 <a href="https://www.cvlibs.net/datasets/kitti/raw_data.php">KITTI dataset 의 raw data</a> 를 사용하고 있는데, 여기에서는 imu data (in the <code class="language-plaintext highlighter-rouge">oxts</code> directory) 가 lidar frame 에 동기화되어 있다 (미리 relative frame 사이의 angular velocity 와 linear acceleration을 preintegration해둔 값을 제공하고 있다 라고 보면 되겠다). 따라서 같은 개수의 파일이 존재한다. 이런 상황에서 <code class="language-plaintext highlighter-rouge">step_size</code> 를 5로 설정한다면, 앞서 말했듯, LiDAR 는 5 frame 마다 한번씩만 보정을 한다. 보정하지 않는 나머지 4 프레임 간격에 대해서는 보정없이, imu only로 propagation 을 한다라고 생각하면 된다. 10hz lidar 인 경우, 0.5초 동안 imu로만 odometry를 수행하는 것과 동일하다. 그렇게 에러가 누적될 때쯤, lidar scan-to-scan matching 을 수행해서 IMU state 의 PVA (position, velocity, attitude) 를 보정해준다. 그러면 IMU는 다시 좋은 상태를 갖게 되고, 다시 한동안 (물론 0.5초와 같이 여전히 짧은 시간 (IMU입장에서는 다소 긴시간일지도) 내에서 말이다) lidar (가 들어오지 않거나) 보정을 받지 못하더라도 어느정도 잘 egomotion estimation 을 해줄 수 있기를 우리는 기대할 수 있다.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Main
        <ol>
          <li><strong>Propagation</strong>
            <ul>
              <li>Propagation 을 위해서는 Pypose의 <code class="language-plaintext highlighter-rouge">IMUPreintegrator</code> 를 사용한다.
                <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">def</span> <span class="nf">propogate</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">propagated_state</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">integrator</span><span class="p">(</span>  <span class="c1"># == forward()</span>
        <span class="n">dt</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">"dt"</span><span class="p">],</span>
        <span class="n">gyro</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">"gyro"</span><span class="p">],</span>
        <span class="n">acc</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">"acc"</span><span class="p">],</span>
        <span class="n">rot</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="nf">get_rotation</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="p">)</span>
</code></pre></div>                </div>
                <ul>
                  <li>더 구체적인 구현 디테일은 <a href="https://github.com/gisbi-kim/mini-pyllio/blob/f0b054d0431d0ff4ade14af50903c08b499769f3/python/llio.py#L97">이 라인</a>을 참고.</li>
                </ul>
              </li>
            </ul>
          </li>
          <li><strong>Correction</strong>
            <ul>
              <li>Correction 단계에서는 먼저 scan-to-scan matching 을 통해서 (imu propagation only보다 정밀해진) relative motion 을 계산 한다. 그리고 이를 직전 pose 에 compose 해서 global pose 를 correct해준다.
                <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># registration and get a more precise relative motion</span>
  <span class="n">pcd</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="nf">downsample_points</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">"velodyne"</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="nb">self</span><span class="p">.</span><span class="nf">cfg</span><span class="p">)</span>
  <span class="n">dx_imu</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">registration</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">pcd</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="nb">self</span><span class="p">.</span><span class="nf">pcd_previous</span><span class="p">)</span>

  <span class="c1"># correct the current global pose</span>
  <span class="n">pose_corrected_prev</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">pose_corrected</span>
  <span class="n">pose_corrected</span> <span class="o">=</span> <span class="n">pose_corrected_prev</span> <span class="err">@</span> <span class="n">dx_imu</span>

  <span class="c1"># update the state of the estimator</span>
  <span class="n">dt_batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">"dt"</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="nb">self</span><span class="p">.</span><span class="nf">cfg</span><span class="p">[</span><span class="s2">"step_size"</span><span class="p">]</span>  <span class="c1"># sec</span>
  <span class="n">corrected_state</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">update_state</span><span class="p">(</span><span class="n">dt_batch</span><span class="p">,</span> <span class="n">pose_corrected</span><span class="p">)</span>
</code></pre></div>                </div>
              </li>
              <li>이 과정에서 어짜피 ICP해서 relative motion 을 구할거면 IMU가 왜 필요한가? 라는 질문을 할 수 있겠다.
                <ul>
                  <li>하지만 ICP는 initial guess 가 좋을 때에만 정답으로의 수렴을 보장할 수 있다.</li>
                  <li>만약 로봇이 고속으로 주행하고 있거나, 혹은 회전하고 있거나, 혹은 동적물체가 너무 많거나 등 다양한 이유로 인해 주변 환경의 structure 가 locally converge 할 위험이 많다.</li>
                  <li>특히 위의 예시에서 step_size 를 5로 설정하고 있는데, 즉 0.5초 전후의 스캔을 정합하려고 하는 것이다. KITTI dataset에서의 자동차의 경우 0.5초 만에 수 meter 를 진행하게 되는데, 수 meter 정도의 translation 이 있을 때 initial guess 없이 (== using identity) ICP 가 수렴하기를 기대하기는 일반적으로 어렵다 (아래 <strong>실험결과</strong>에서 정량적으로 알아보았다).</li>
                  <li>그래서 아래와 같이 IMU 가 propagate 한 relative motion 을 이용해서 initial guess 를 공급해주면 ICP가 더 잘 수행될 수 있기 때문에, IMU가 LiDAR에게 필요한 것이다.
                    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">dx_imu_initial</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">relative_pose_propagated</span>
  <span class="n">dx_lidar_initial</span> <span class="o">=</span> <span class="n">i2v</span> <span class="err">@</span> <span class="n">dx_imu_initial</span> <span class="err">@</span> <span class="n">v2i</span> <span class="c1"># important!</span>
  <span class="n">icplib</span> <span class="o">=</span> <span class="n">o3d</span><span class="p">.</span><span class="nf">pipelines</span><span class="p">.</span><span class="nf">registration</span>
  <span class="n">dx_lidar</span> <span class="o">=</span> <span class="n">icplib</span><span class="p">.</span><span class="nf">registration_generalized_icp</span><span class="p">(</span>
      <span class="n">source</span><span class="p">,</span>
      <span class="n">target</span><span class="p">,</span>
      <span class="nb">self</span><span class="p">.</span><span class="nf">cfg</span><span class="p">[</span><span class="s2">"icp_inlier_threshold"</span><span class="p">],</span>
      <span class="n">dx_lidar_initial</span><span class="p">,</span>
      <span class="n">icplib</span><span class="o">.</span><span class="no">TransformationEstimationForGeneralizedICP</span><span class="p">(),</span>
  <span class="p">).</span><span class="nf">transformation</span>
</code></pre></div>                    </div>
                    <ul>
                      <li>Tip: 이 때 <code class="language-plaintext highlighter-rouge">error = np.linalg.inv(dx_lidar) @ dx_lidar_initial</code> 와 같이 initial guess 와 ICP로 부터 얻은 transform 사이의 차이를 계산해보면, IMU가 얼마나 좋은 initial 을 공급해주는 지 알아볼 수 있다. step size 를 1이나 2로 설정할 경우 거의 수 cm 수준만의 차이를 보이는 것을 알 수 있다.</li>
                      <li>PS: 물론 IMU없이 LiDAR 만으로도 robust 한 local keypoint matching 을 통해 좋은 registration initial 을 만들어 줄 수도 있다 (예시: <a href="http://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html">Open3D’s global registration</a>, or <a href="https://github.com/url-kaist/Quatro">Quatro ICRA22</a>). 하지만 IMU 가 갖는 장점은, 이런 방식들에 비해 (propagation하는 것은) 추가적인 비용이 거의 들지 않는다는 것이다! 물론 어느쪽이 항상 더 낫다 라고 말할 수는 없는 것이고, point cloud 센서 데이터만 덩그러니 주어지는 상황인가, 혹은 a robot 이 real-time 으로 recursively state 를 예측해나가는 상황인가, 에 따라 엔지니어가 자원과 요구사항을 고려해서 적절하게 선택해야 할 것이다.</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>이렇게 계산한 보정된 relative motion 을 이용해서 global pose 를 correction 해준다.
                <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">update_state</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">dt_batch</span><span class="p">,</span> <span class="n">pose_corrected</span><span class="p">):</span>
    <span class="c1"># prepare</span>
    <span class="n">global_pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">pose_corrected</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">pose_corrected_prev</span> <span class="o">=</span> <span class="nb">self</span><span class="p">.</span><span class="nf">pose_corrected</span>
    <span class="n">global_delta_pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span>
        <span class="n">pose_corrected</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">pose_corrected_prev</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">global_vel</span> <span class="o">=</span> <span class="n">global_delta_pos</span> <span class="o">/</span> <span class="n">dt_batch</span>

    <span class="n">global_rot</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="no">SO3</span><span class="p">(</span><span class="no">R</span><span class="p">.</span><span class="nf">from_matrix</span><span class="p">(</span><span class="n">pose_corrected</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]).</span><span class="nf">as_quat</span><span class="p">())</span>

    <span class="c1"># update (loosely coupled, thus do explicit replacement) the engine state</span>
    <span class="nb">self</span><span class="p">.</span><span class="nf">integrator</span><span class="p">.</span><span class="nf">pos</span> <span class="o">=</span> <span class="n">global_pos</span>
    <span class="nb">self</span><span class="p">.</span><span class="nf">integrator</span><span class="p">.</span><span class="nf">vel</span> <span class="o">=</span> <span class="n">global_vel</span>
    <span class="nb">self</span><span class="p">.</span><span class="nf">integrator</span><span class="p">.</span><span class="nf">rot</span> <span class="o">=</span> <span class="n">global_rot</span>
</code></pre></div>                </div>
                <ul>
                  <li>이 과정에서 integrator 내부의 state 를 그냥 바꿔치기 하는 셈이므로 <strong>loosely coupled</strong> lidar-inertial odometry system 이라고 말할 수 있다. correction 과정에서 IMU는 LiDAR에게 initial 을 독립적으로 제공하고, 실제로 보정치는 LiDAR registration 만으로 이루어졌기 때문이다.</li>
                </ul>
              </li>
            </ul>
          </li>
        </ol>
      </li>
    </ol>
  </li>
</ul>

<h2 id="실험-결과">실험 결과</h2>
<ul>
  <li>세팅
    <ul>
      <li>LiDAR registration할 때 point cloud 는 <a href="https://github.com/gisbi-kim/mini-pyllio/blob/f0b054d0431d0ff4ade14af50903c08b499769f3/python/cfg.yml#L20">0.5m 로 voxel downsampling</a> 하였다.</li>
      <li><code class="language-plaintext highlighter-rouge">2011_09_30_0018</code> 시퀀스에 대해 실험하였다.</li>
    </ul>
  </li>
  <li><strong>Ablations for each comparison methods</strong>
    <p align="center">
  <img src="/assets/data/2023-01-09-imu-lidar-fusion2/result1.png" width="1500" />
</p>
  </li>
  <li><strong>Z 비교</strong>
    <p align="center">
  <img src="/assets/data/2023-01-09-imu-lidar-fusion2/result2.png" width="900" />
</p>
  </li>
  <li><strong>요약</strong>
    <ul>
      <li>LiDAR only 는 scan과 scan 사이 간격이 멀어질 수록 initial guess 없이는 fail하는 것을 볼 수 있다.</li>
      <li>GT rotation 을 공급한 것보다, sparse 하더라도 lidar 로 보정한 것이 더 안정적인 결과를 보여주는 것을 알 수 있다.</li>
    </ul>
  </li>
</ul>

<h1 id="결론">결론</h1>
<ul>
  <li>IMU only odometry 는 외부 도움 없이는 금방 발산한다.</li>
  <li>Python 만 이용해서 간단하게 Loosely-coupled LiDAR + IMU 기반 Odometry system을 구현해보았다.</li>
  <li>LiDAR가 rough 하게만 쓰여도 (i.e., 0.5m resolution, 0.5sec 마다 한 번만 보정), IMU state 를 잘 보정할 수 있음을 실험적으로 알아보았다.</li>
  <li>이렇게 PVA가 잘 보정된 IMU는 그 다음턴의 LiDAR registration 을 위한 좋은 initial guess 를 생성해주고, 결과적으로 선순환이 반복된다.</li>
</ul>

  </div>

  <hr style="border:1px foo rgb(193, 198, 200)"><div id="disqus_thread" style="margin-top:25px"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'http://localhost:4000/slam/2023/01/09/imu-lidar-fusion2.html';
      this.page.identifier = 'http://localhost:4000/slam/2023/01/09/imu-lidar-fusion2.html';
    };
    (function () {
      var d = document, s = d.createElement('script');
      s.src = 'https://robotics.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments
      powered by Disqus.</a></noscript></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://www.linkedin.com/in/giseop-kim-71683088" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://scholar.google.com/citations?user=9mKOLX8AAAAJ&hl=ko&oi=ao" target="_blank">
          <li>
            <i class="ai ai-google-scholar"></i>
          </li>
        </a><a href="https://github.com/gisbi-kim" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://bit.ly/giseopkim" target="_blank">
          <li>
            <i class="fa fa-user" style="font-size: 2.09em;"></i>
            <!-- <i> notion</i> -->
            <!-- <i class="fa fa-user"></i> -->
          </li>
        </a><a href="https://youtube.com/channel/UCrmVMJ3KEFbDD9EtnAmDT6g" target="_blank">
          <li>
            <i class="icon-youtube"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2023</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/assets/js/darkmode.js"></script>
  
  <script src="/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/assets/js/search.js"></script>
  
</body>

</html>
